"""
ü§ñ Local AI Service - 100% Open Source
Integra√ß√£o com Ollama para gera√ß√£o de scripts usando LLMs locais
"""

import ollama
import logging
from typing import Dict, List, Optional
import json

logger = logging.getLogger(__name__)


class LocalAIService:
    """Servi√ßo de IA Local usando Ollama"""
    
    def __init__(self, model: str = "llama3.1:8b"):
        """
        Inicializa o servi√ßo de IA local
        
        Args:
            model: Nome do modelo Ollama (padr√£o: llama3.1:8b)
        """
        self.model = model
        self._check_ollama_connection()
    
    def _check_ollama_connection(self):
        """Verifica se o Ollama est√° rodando"""
        try:
            ollama.list()
            logger.info(f"‚úÖ Ollama conectado! Modelo: {self.model}")
        except Exception as e:
            logger.error(f"‚ùå Erro ao conectar com Ollama: {e}")
            logger.warning("‚ö†Ô∏è Certifique-se de que o Ollama est√° rodando: 'ollama serve'")
    
    def generate_script(
        self,
        topic: str,
        style: str = "viral",
        duration: int = 60,
        platform: str = "tiktok"
    ) -> Dict[str, any]:
        """
        Gera um script para v√≠deo curto usando LLM local
        
        Args:
            topic: T√≥pico do v√≠deo
            style: Estilo do v√≠deo (viral, educativo, engra√ßado, etc.)
            duration: Dura√ß√£o alvo em segundos
            platform: Plataforma (tiktok, youtube, instagram)
        
        Returns:
            Dict com script, t√≠tulo, hashtags e cenas
        """
        
        prompt = self._build_script_prompt(topic, style, duration, platform)
        
        # Tenta gerar at√© 2 vezes
        max_retries = 2
        for attempt in range(max_retries):
            try:
                logger.info(f"üîÑ Tentativa de gera√ß√£o {attempt + 1}/{max_retries}...")
                
                response = ollama.chat(
                    model=self.model,
                    messages=[
                        {
                            'role': 'system',
                            'content': 'Voc√™ √© um roteirista profissional. Responda APENAS com JSON v√°lido.'
                        },
                        {
                            'role': 'user',
                            'content': prompt
                        }
                    ],
                    options={
                        'temperature': 0.7,
                        'top_p': 0.9,
                        'num_ctx': 8192,     # Contexto aumentado drasticamente
                        'num_predict': 4096, # Permitir resposta muito longa
                    }
                )
                
                content = response['message']['content']
                
                # Tenta limpar o conte√∫do para encontrar JSON
                json_content = self._extract_json_from_text(content)
                
                if json_content:
                    result = json.loads(json_content)
                    
                    # Valida se tem campos obrigat√≥rios
                    if "script" in result and len(result.get("script", "").split()) > 50:
                        logger.info(f"‚úÖ Script gerado com sucesso na tentativa {attempt + 1}")
                        return result
                    else:
                        logger.warning(f"‚ö†Ô∏è JSON gerado, mas script muito curto. Tentando novamente...")
                
            except Exception as e:
                logger.error(f"‚ùå Erro na tentativa {attempt + 1}: {e}")
                
        # Se falhar todas as tentativas, usa fallback, mas com aviso
        logger.error("‚ùå Falha em todas as tentativas de gera√ß√£o. Usando fallback.")
        return self._get_fallback_script(topic, style)

    def _extract_json_from_text(self, text: str) -> Optional[str]:
        """Tenta encontrar e extrair bloco JSON dentro de um texto"""
        try:
            # Procura pelo primeiro '{' e √∫ltimo '}'
            start = text.find('{')
            end = text.rfind('}')
            
            if start != -1 and end != -1:
                return text[start:end+1]
            return None
        except:
            return None
    
    def _build_script_prompt(
        self,
        topic: str,
        style: str,
        duration: int,
        platform: str
    ) -> str:
        """Constr√≥i o prompt para gera√ß√£o de script"""
        
        # L√ìGICA MATEM√ÅTICA OBRIGAT√ìRIA
        # 2.5 palavras por segundo √© a m√©dia padr√£o de fala confort√°vel
        words_count_min = int(duration * 2.3)
        words_count_target = int(duration * 2.5)
        
        # Calcula n√∫mero de cenas baseado na dura√ß√£o
        num_scenes = max(3, duration // 12)
        scene_duration = duration // num_scenes
        
        prompt = f"""
Voc√™ √© um roteirista profissional de elite.

TAREFA: Escrever um roteiro para v√≠deo de EXATAMENTE {duration} segundos.
T√ìPICO: "{topic}"

‚ö†Ô∏è REGRA MATEM√ÅTICA DE OURO (Siga ou o script falhar√°):
Para preencher {duration} segundos, voc√™ PRECISA escrever entre {words_count_min} e {words_count_target} palavras.
N√ÉO escreva menos que {words_count_min} palavras sob nenhuma circunst√¢ncia.

ESTRUTURA OBRIGAT√ìRIA (JSON V√ÅLIDO):
{{
  "titulo": "T√≠tulo Viral (Max 50 chars)",
  "script": "Texto COMPLETO da narra√ß√£o. DEVE ter pelo menos {words_count_min} palavras.",
  "cenas": [
    {{
      "visual": "Descri√ß√£o visual DETALHADA em ingl√™s (Prompt para Stable Diffusion)",
      "narra√ß√£o": "Trecho da narra√ß√£o correspondente a esta cena (~{scene_duration}s)"
    }}
  ]
}}

REQUISITOS DE CONTE√öDO:
1. Estilo: {style.upper()}
2. Plataforma: {platform.upper()}
3. O script deve ser denso, informativo e direto. Sem "Ol√° pessoal" ou introdu√ß√µes longas.
4. Divida em exatamente {num_scenes} cenas.
5. As descri√ß√µes visuais DEVEM ser em INGL√äS, detalhadas e cinematogr√°ficas (ex: "Cinematic shot of..., 8k, unreal engine").

Responda APENAS com o JSON.
"""
        return prompt
    
    def _parse_text_response(self, text: str, topic: str) -> Dict:
        """Parseia resposta em texto puro caso n√£o seja JSON"""
        
        lines = [line.strip() for line in text.split('\n') if line.strip()]
        
        return {
            "titulo": f"{topic} - Voc√™ Precisa Ver Isso!",
            "gancho": lines[0] if lines else "Voc√™ n√£o vai acreditar nisso!",
            "script": text,
            "cta": "Curte e segue para mais!",
            "hashtags": [f"#{topic.lower().replace(' ', '')}", "#viral", "#fyp"],
            "cenas": [
                {
                    "tempo": "0-60s",
                    "narra√ß√£o": text,
                    "visual": f"Imagens relacionadas a {topic}"
                }
            ]
        }
    
    def _get_fallback_script(self, topic: str, style: str) -> Dict:
        """Script de fallback caso a IA falhe"""
        
        return {
            "titulo": f"{topic.title()} - Inacredit√°vel!",
            "gancho": f"Voc√™ sabia que {topic.lower()} pode mudar tudo?",
            "script": f"Hoje vou te mostrar algo incr√≠vel sobre {topic}. Isso vai mudar completamente sua perspectiva. Fica at√© o final que voc√™ vai se surpreender!",
            "cta": "Curte e segue para mais conte√∫dos incr√≠veis!",
            "hashtags": [f"#{topic.lower().replace(' ', '')}", "#viral", "#fyp", "#brasil"],
            "cenas": [
                {
                    "tempo": "0-20s",
                    "narra√ß√£o": f"Voc√™ sabia que {topic.lower()} pode mudar tudo?",
                    "visual": f"Imagem impactante sobre {topic}"
                },
                {
                    "tempo": "20-40s",
                    "narra√ß√£o": "Hoje vou te mostrar algo incr√≠vel sobre isso.",
                    "visual": "Demonstra√ß√£o visual"
                },
                {
                    "tempo": "40-60s",
                    "narra√ß√£o": "Curte e segue para mais conte√∫dos incr√≠veis!",
                    "visual": "CTA visual"
                }
            ]
        }
    
    def generate_title(self, script: str, style: str = "viral") -> str:
        """
        Gera um t√≠tulo viral para o v√≠deo
        
        Args:
            script: Script do v√≠deo
            style: Estilo do t√≠tulo
        
        Returns:
            T√≠tulo otimizado
        """
        
        prompt = f"""
Crie um t√≠tulo VIRAL e CLICKBAIT para este v√≠deo:

Script: "{script[:200]}..."

Regras:
- M√°ximo 60 caracteres
- Portugu√™s do Brasil
- Estilo: {style}
- Usar emojis estrat√©gicos
- Gerar curiosidade/urg√™ncia
- N√£o usar pontos finais

Responda APENAS com o t√≠tulo, sem aspas ou explica√ß√µes.
"""
        
        try:
            response = ollama.chat(
                model=self.model,
                messages=[{'role': 'user', 'content': prompt}],
                options={'temperature': 0.9}
            )
            
            title = response['message']['content'].strip().strip('"\'')
            return title[:60]  # Limita a 60 caracteres
            
        except Exception as e:
            logger.error(f"‚ùå Erro ao gerar t√≠tulo: {e}")
            return "Voc√™ N√£o Vai Acreditar Nisso! üò±"
    
    def improve_script(self, script: str, feedback: str) -> str:
        """
        Melhora um script existente baseado em feedback
        
        Args:
            script: Script original
            feedback: Feedback do usu√°rio
        
        Returns:
            Script melhorado
        """
        
        prompt = f"""
Script Original:
{script}

Feedback do Usu√°rio:
{feedback}

Reescreva o script incorporando o feedback, mantendo o estilo viral e envolvente.
Responda APENAS com o novo script, sem explica√ß√µes.
"""
        
        try:
            response = ollama.chat(
                model=self.model,
                messages=[{'role': 'user', 'content': prompt}]
            )
            
            return response['message']['content'].strip()
            
        except Exception as e:
            logger.error(f"‚ùå Erro ao melhorar script: {e}")
            return script  # Retorna o original se falhar


# Inst√¢ncia global do servi√ßo
_ai_service = None

def get_ai_service(model: str = "llama3.1:8b") -> LocalAIService:
    """Retorna inst√¢ncia singleton do servi√ßo de IA"""
    global _ai_service
    if _ai_service is None:
        _ai_service = LocalAIService(model=model)
    return _ai_service


# Fun√ß√µes de conveni√™ncia
def generate_script(topic: str, **kwargs) -> Dict:
    """Atalho para gerar script"""
    service = get_ai_service()
    return service.generate_script(topic, **kwargs)


def generate_title(script: str, **kwargs) -> str:
    """Atalho para gerar t√≠tulo"""
    service = get_ai_service()
    return service.generate_title(script, **kwargs)
